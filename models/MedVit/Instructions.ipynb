{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Install Requirement"
      ],
      "metadata": {
        "id": "gz6CwD6MRWFs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD9uOPEK65K0"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git\n",
        "%cd /content/MedViT"
      ],
      "metadata": {
        "id": "9AwVn7yc7Soj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "RPHDM3KwQ4Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "import torchattacks\n",
        "from torchattacks import PGD, FGSM"
      ],
      "metadata": {
        "id": "lgm5vmQp8i9h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PyTorch\", torch.__version__)\n",
        "print(\"Torchvision\", torchvision.__version__)\n",
        "print(\"Torchattacks\", torchattacks.__version__)\n",
        "print(\"Numpy\", np.__version__)\n",
        "print(\"Medmnist\", medmnist.__version__)"
      ],
      "metadata": {
        "id": "deLoJPfDTDWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "nIefIFDW80-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data_flag =  \n",
        "[tissuemnist, pathmnist, chestmnist, dermamnist, octmnist, pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]"
      ],
      "metadata": {
        "id": "rVNzCWaVUd_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'retinamnist'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "lr = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "print(\"number of channels : \", n_channels)\n",
        "print(\"number of classes : \", n_classes)"
      ],
      "metadata": {
        "id": "rH1INOxS8-iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "TD22o8uW9L1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "id": "eNjqCTnI9T9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "1ta2wQYk78Mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MedViTs ---> [MedViT_small, MedViT_base, MedViT_large]"
      ],
      "metadata": {
        "id": "a17pPgePWXga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from MedViT import MedViT_small, MedViT_base, MedViT_large\n",
        "\n",
        "model = MedViT_small(num_classes = n_classes).cuda()\n",
        "#model = MedViT_base(num_classes = n_classes).cuda()\n",
        "#model = MedViT_large(num_classes = n_classes).cuda()"
      ],
      "metadata": {
        "id": "GEQ5S3_U8E0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea09038-9e57-42ab-b767-592098af81ba"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "g-ImKp2m9cLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "gMy_aJrE9eeM"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print('Epoch [%d/%d]'% (epoch+1, NUM_EPOCHS))\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "KmIo3JWf9lEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "XRkfM6CM91j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split = 'test'\n",
        "\n",
        "model.eval()\n",
        "y_true = torch.tensor([])\n",
        "y_score = torch.tensor([])\n",
        "\n",
        "data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in data_loader:\n",
        "        inputs = inputs.cuda()\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.softmax(dim=-1)\n",
        "        y_score = torch.cat((y_score, outputs.cpu()), 0)\n",
        "\n",
        "    y_score = y_score.detach().numpy()\n",
        "\n",
        "    evaluator = Evaluator(data_flag, split, size=224)\n",
        "    metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "    print('%s  auc: %.3f  acc: %.3f' % (split, *metrics))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdC1Gg98RU37",
        "outputId": "11f6b052-2ac0-4080-c31d-cb5c4cdf0ccc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  auc: 0.623  acc: 0.472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adversarial Robustness"
      ],
      "metadata": {
        "id": "XH1WvchMX5L0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reduce bach size for GPU limitation"
      ],
      "metadata": {
        "id": "GER2-X0Yc1ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 5\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "rNHm98NaZjZ5"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "atk = FGSM(model, eps=0.01)\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    labels = labels.squeeze(1)\n",
        "    images = atk(images, labels).cuda()\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels.cuda()).sum()\n",
        "\n",
        "print('FGSM Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
      ],
      "metadata": {
        "id": "TK4kV6p9YiZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "atk = PGD(model, eps=8/255, alpha=4/255, steps=10, random_start=True)\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    labels = labels.squeeze(1)\n",
        "    images = atk(images, labels).cuda()\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels.cuda()).sum()\n",
        "\n",
        "print('PGD Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
      ],
      "metadata": {
        "id": "76g3n07lcW8x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}